<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <title>Dr. Duy-Linh Nguyen's cv</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="../MyResume/assets/img/5x5_2024.jpg" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Fonts -->
  <link href="https://fonts.googleapis.com" rel="preconnect">
  <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Raleway:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Main CSS File -->
  <link href="assets/css/main.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: MyResume
  * Template URL: https://bootstrapmade.com/free-html-bootstrap-template-my-resume/
  * Updated: Jun 29 2024 with Bootstrap v5.3.3
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body class="index-page">

  <header id="header" class="header d-flex flex-column justify-content-center">

    <i class="header-toggle d-xl-none bi bi-list"></i>

    <nav id="navmenu" class="navmenu">
      <ul>
        <li><a href="#hero" class="active"><i class="bi bi-house navicon"></i><span>Home</span></a></li>
        <li><a href="#about"><i class="bi bi-person navicon"></i><span>About</span></a></li>
		<li><a href="#publication"><i class="bi bi-journal"></i><span>Publications</span></a></li>
        <li><a href="#resume"><i class="bi bi-file-earmark-text navicon"></i><span>Resume</span></a></li>
        <li><a href="#portfolio"><i class="bi bi-pencil-square"></i><span>Research Activities</span></a></li>
        <li><a href="#services"><i class="bi bi-images navicon"></i><span>Awards</span></a></li>
		<li><a href="#partners"><i class="bi bi-people-fill"></i><span>Partners</span></a></li>
        <li><a href="#contact"><i class="bi bi-envelope navicon"></i><span>Contact</span></a></li>
      </ul>
    </nav>

  </header>

  <main class="main">

    <!-- Hero Section -->
    <section id="hero" class="hero section light-background">

      <img src="assets/img/UOU+Linh.jpg" alt="">

      <div class="container" data-aos="zoom-out">
        <div class="row justify-content-center">
          <div class="col-lg-9">
            <h2>Duy-Linh Nguyen</h2>
			<h3>(Nguyễn Duy Linh)</h3>
            <p><span class="typed" data-typed-items="Ph.D in AI and Computer Vision, Postdoctoral Researcher"></span><span class="typed-cursor typed-cursor--blink" aria-hidden="true"></span></p>
            <div class="social-links">
              <a href="https://scholar.google.co.kr/citations?user=nq112_4AAAAJ&hl=en"><i class="bi bi-google"></i></a>
              <a href="https://www.linkedin.com/in/duy-linh-nguyen-619b81134/"><i class="bi bi-linkedin"></i></a>
              <a href="https://x.com/ndlinh301"><i class="bi bi-twitter-x"></i></a>
              <a href="https://www.facebook.com/nguyenduylinhlh"><i class="bi bi-facebook"></i></a>
              <a href="https://www.instagram.com/nguyenduylinhlh/"><i class="bi bi-instagram"></i></a>      
              <a href="https://www.tiktok.com/@ndlinh301"><i class="bi bi-tiktok"></i></a>            </div>
          </div>
        </div>
      </div>

    </section><!-- /Hero Section -->

    <!-- About Section -->
    <section id="about" class="about section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>About</h2>
        <!-- <p>Magnam dolores commodi suscipit. Necessitatibus eius consequatur ex aliquid fuga eum quidem. Sit sint consectetur velit. Quisquam quos quisquam cupiditate. Et nemo qui impedit suscipit alias ea. Quia fugiat sit in iste officiis commodi quidem hic quas.</p> -->
</div>
      <!-- End Section Title -->

      <div class="container" data-aos="fade-up" data-aos-delay="100">

        <div class="row gy-4 justify-content-center">
          <div class="col-lg-4">
            <img src="assets/img/5x5_2024.jpg" class="img-fluid" alt="">
          </div>
          <div class="col-lg-8 content">
            <h1>Dr. Duy-Linh Nguyen</h1>
			<h3>(Nguyễn Duy Linh)</h3>
            <p class="fst-italic py-3">
              <!-- Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore
              magna aliqua. -->
            </p>
            <div class="row">
              <div class="col-lg-6">
                <ul>
                  <li><i class="bi bi-chevron-right"></i> <strong>Birthday:</strong> <span>30 Jan 1985</span></li>
                  <!-- <li><i class="bi bi-chevron-right"></i> <strong>Website:</strong> <span>www.example.com</span></li> -->
                  <li><i class="bi bi-chevron-right"></i> <strong>Phone:</strong> <span>+82 010 5953 5249</span></li>
                  <li><i class="bi bi-chevron-right"></i> <strong>Email:</strong> <span>ndlinh301@mail.ulsan.ac.kr
				  nguyenduylinhqbu@gmail.com</span></li>
                  <li><i class="bi bi-chevron-right"></i> <strong>Address</Address>:</strong> <span>7-104, University of Ulsan, South Korea</span></li>
                </ul>
              </div>
              <div class="col-lg-6">
                <ul>
                  <li><i class="bi bi-chevron-right"></i> <strong>Country:</strong> <span>Vietnam</span></li>
                  <li><i class="bi bi-chevron-right"></i> <strong>Hobby:</strong> <span>Research, Sport, Music</span></li>
                  <li><i class="bi bi-chevron-right"></i> <strong>Research Interest:</strong> <span>Computer Vision, Machine Learning, Images Processing</span></li>
                  <!-- <li><i class="bi bi-chevron-right"></i> <strong>Address</Address>:</strong> <span>University of Ulsan, South Korea</span></li> -->
                </ul>
              </div>
            </div>
            <p class="py-3" style="text-align: justify;">
              Dr. DUY-LINH NGUYEN received a Bachelor of Engineering degree in Applied Informatics from the Vinh University of Technology Education, Vinh, Vietnam, in 2010; a Master’s in Computer Science from the University of Danang, Danang, Vietnam, in 2014; and a Ph.D. in Electrical Engineering from the Department of Electrical, Electronic, and Computer Engineering, University of Ulsan, Ulsan, South Korea, in 2023. After earning his Bachelor’s degree, he joined the Information Technology and Electrical Engineering Department, Quang Binh University (QBU), Quang Binh Province, Vietnam, as a Lecturer. He currently is with the Intelligent System Laboratory (ISLab), Department of Electrical, Electronic, and Computer Engineering, University of Ulsan. His research interests include object detection and recognition in computer vision based on machine learning.
            </p>
          </div>
        </div>

      </div>

    </section><!-- /About Section -->

    <!-- Stats Section -->
    <section id="stats" class="stats section">

      <div class="container" data-aos="fade-up" data-aos-delay="100">

        <div class="row gy-4">

          <div class="col-lg-3 col-md-6 d-flex flex-column align-items-center">
            <i class="bi-journal-text"></i>
            <div class="stats-item">
              <span data-purecounter-start="0" data-purecounter-end="80" data-purecounter-duration="1" class="purecounter"></span>
              <p>Publications</p>
            </div>
          </div><!-- End Stats Item -->

          <div class="col-lg-3 col-md-6 d-flex flex-column align-items-center">
            <i class="bi bi-clipboard2-pulse"></i>
            <div class="stats-item">
              <span data-purecounter-start="0" data-purecounter-end="245" data-purecounter-duration="1" class="purecounter"></span>
              <p>Citations</p>
            </div>
          </div><!-- End Stats Item -->

          <div class="col-lg-3 col-md-6 d-flex flex-column align-items-center">
            <i class="bi bi-journal-bookmark"></i>
            <div class="stats-item">
              <span data-purecounter-start="0" data-purecounter-end="7" data-purecounter-duration="1" class="purecounter"></span>
              <p>H-index</p>
            </div>
          </div><!-- End Stats Item -->

          <div class="col-lg-3 col-md-6 d-flex flex-column align-items-center">
          <i class="bi bi-journal-bookmark-fill"></i>
          <div class="stats-item"> <span data-purecounter-start="0" data-purecounter-end="7" data-purecounter-duration="1" class="purecounter"></span>
              <p>i10-index</p>
          </div>
          </div>
          <!-- End Stats Item -->

        </div>

      </div>

    </section><!-- /Stats Section -->
	<!-- Publication Section -->
<section id="publication" class="publication">
	<div class="container section-title" data-aos="fade-up">
		<h2 class="stats-item">International Journal </h2>
	</div>
	<div>
	<h3> 2024</h3>
	<ol>
		<li><strong>Muhamad Dwisnanto Putro</strong>, Adri Priadana, Duy-Linh Nguyen, Kang-Hyun Jo,  EMOTIZER: A Multi-pose Facial Emotion Recognizer Using RGB Camera Sensor on Low-cost Devices, IEEE Sensors, pp.1-11, November 2024.</li>
	
	</ol>
	
	</div>
	<div>
	<div>
	<h3> 2023</h3>
	<ol>
		<li><strong>Duy-Linh Nguyen</strong>, Muhamad Dwisnanto Putro and Kang-Hyun Jo, Lightweight CNN-Based Driver Eye Status Surveillance for Smart Vehicles, IEEE Transactions on Industrial Informatics, 2023.</li>
		<li><strong>Duy-Linh Nguyen</strong>, Muhamad Dwisnanto Putro, Kang-Hyun Jo, Lightweight Convolutional Neural Network for Fire Classification in Surveillance System, IEEE Access, 2023. </li>
		<li><strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Adri Priadana, Kang-Hyun Jo, Car Detection for Smart Parking Systems Based on Improved YOLOv5, Vietnam Journal of Computer science, 2023.</li>
		
	</ol>
	
	</div>
	<div>
	<h3> 2022</h3>
	<ol>
		<li><strong>Duy-Linh Nguyen</strong>, Muhamad Dwisnanto Putro, Kang-Hyun Jo, Facemask Wearing Alert System Based on Simple Architecture with Low-Computing Devices, IEEE Access, Vol.10, pp.29972-29981, 3 2022.</li>
		<li><strong>Duy-Linh Nguyen</strong>, Muhamad Dwisnanto Putro, Kang-Hyun Jo, Driver Behaviors Recognizer based on Light-weight Convolutional Neural Network Architecture and Attention Mechanism, IEEE Access, Vol.10, pp.71019 - 71029, 6 2022. </li>
		<li>Muhamad Dwisnanto Putro, <strong>Duy-Linh Nguyen</strong>, Kang-Hyun Jo, An Efficient Face Detector on a CPU Using Dual-Camera Sensors for Intelligent Surveillance Systems, IEEE Sensors, Vol.22, No.1, pp.565 - 574, 1 2022.</li>
		<li> Muhamad Dwisnanto Putro, <strong>Duy-Linh Nguyen</strong>, Kang-Hyun Jo, A Fast CPU Real-time Facial Expression Detector using Sequential Attention Network for Human-robot Interaction, IEEE Transactions on Industrial Informatics, Vol.18, 11 2022.</li>
	</ol>
	</div>
	<!-- Internataional conferences -->
	<div class="container section-title" data-aos="fade-up">
		<h2 class="stats-item">Internataional conferences </h2>
	</div>
	<div>
		<h3> 2024</h3>
		<ol>
			<li>Adri Priadana, <strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Jehwan Choi, Kang-Hyun Jo, Wider Neighborhood-Aware Attention in Improving YOLOv8n for One-Stage Human Fall Detection, IECON 2024, Chicago, USA, Nov 3, 2024.</li>
			<li><strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Adri Priadana, Jehwan Choi, Kang-Hyun Jo, Pothole and Manhole Cover Detection for Road Safety Systems, IECON 2024, Chicago, USA, Nov 3, 2024.</li>
			<li>Xuan-Thuy Vo, <strong>Duy-Linh Nguyen</strong>, Adri Priadana, Kang-Hyun Jo, Efficient Vision Transformers with Partial Attention, ECCV 2024, Milano, Italy, Sep 29, 2024.  </li>
			<li><strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Adri Priadana, Kang-Hyun Jo, Simple Human Fall Surveillance System Based on Person Detection, IWIS 2024, Ulsan, Korea, Aug 28, 2024.</li>
			<li>Adri Priadana, <strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Cao Ge, Kang-Hyun Jo, Facial Attribute Recognition using Weighted Bottleneck Transformer for Intelligent Marketing, IWIS 2024, Ulsan, Korea, Aug 28, 2024.</li>
			<li>Xuan-Thuy Vo, <strong>Duy-Linh Nguyen</strong>, Adri Priadana, Kang-Hyun Jo, Refining Attention Maps for Vision Transformer, IWIS 2024, Ulsan, Korea, Aug 28, 2024. </li>
			<li><strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Adri Priadana, Jehwan Choi, Kang-Hyun Jo, Improved Tomato Detector Supporting for Automatic Harvesting Systems, CITA 2024 (Special Session on CV), Hoi An & Danang, Vietnam, Jul 19, 2024.</li>
			<li>Xuan-Thuy Vo, <strong>Duy-Linh Nguyen</strong>, Adri Priadana, Jehwan Choi, Kang-Hyun Jo, Multi-scale Convolutions Meet Group Attention for Dense Prediction Tasks, CITA 2024 (Special Session on CV), Hoi An & Danang, Vietnam, Jul 19, 2024.</li>
			<li>Jehwan Choi, <strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Kang-Hyun Jo, Small Object Detection without Attention for Aerial Surveillance, CITA 2024 (Special Session on CV) CITA 2024, Hoi An & Danang, Vietnam, Jul 19, 2024.</li>
			<li>Adri Priadana, <strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Ashraf Uddin Russo, Kang-Hyun Jo, EMPCNet: Facial Attribute Recognition using Efficient Multi-Perspective Convolution for Human?Robot Interaction, HSI 2024, Paris, France, Jul 8, 2024.</li>
			<li><strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Adri Priadana, Muhamad Dwisnanto Putro, Kang-Hyun Jo, Fruit Ripeness Detector for Automatic Fruit Classification Systems, ISIE 2024, Ulsan, Korea, Jun 18, 2024.</li>
			<li>Adri Priadana, <strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Muhamad Dwisnanto Putro, Cao Ge, Kang-Hyun Jo, Simultaneous Facial Age Group and Gender Recognition using Efficient Local-Global Attention Network for Intelligent Advertising, ISIE 2024, Ulsan, Korea, Jun 18, 2024.</li>
			<li>Xuan-Thuy Vo, <strong>Duy-Linh Nguyen</strong>, Adri Priadana, and Kang-Hyun Jo, Reweighting Foveal Visual Representations, ISIE 2024, Ulsan, Korea, Jun 18, 2024.</li>
			<li>Muhamad Dwisnanto Putro, Adri Priadana, <strong>Duy-Linh Nguyen</strong>, Kang-Hyun Jo, Lightweight CPU-based Face detection with Efficient Feature Selector in Real-time Applications, ISIE 2024, Ulsan, Korea, Jun 18, 2024.</li>
			<li><strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Adri Priadana, Kang-Hyun Jo, Minor Object Recognition from Drone Image Sequence, IW-FCV2024, Tokyo, Japan, Feb 19, 2024.</li>
			<li>Adri Priadana, <strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Kang-Hyun Jo, Human Facial Age Group Recognizer using Assisted Bottleneck Transformer Encoder, IW-FCV2024, Tokyo, Japan, Feb 19, 2024.</li>
			<li>Xuan-Thuy Vo, <strong>Duy-Linh Nguyen</strong>, Adri Priadana, and Kang-Hyun Jo, Bidirectional Local-to-Global Attentions for Visual Representation, IW-FCV2024, Tokyo, Japan, Feb 19, 2024.</li>
		</ol>
	</div>
	
	<div>
		<h3> 2023</h3>
		<ol>
			<li>Adri Priadana, Muhamad Dwisnanto Putro, Jinsu An, <strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Kang-Hyun Jo, Facial Attribute Recognition using Lightweight Multi-Label CNN-Transformer Architecture for Intelligent Advertising, IECON 2023, Singapore, Oct 16, 2023.</li>
			<li><strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Adri Priadana, Kang-Hyun Jo, Vehicle Detector Based on YOLOv5 Architecture for Traffic Management and Control Systems, IECON 2023, Singapore, Oct 16, 2023.</li>
			<li><strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Adri Priadana, Kang-Hyun Jo, Simultaneous Person, Face, and Hand Detector Based on Improved YOLOv5, IWIS2023, Ulsan, Korea, Aug 9, 2023.</li>
			<li>Adri Priadana, Muhamad Dwisnanto Putro, Jinsu An, <strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Kang-Hyun Jo, Gender Recognizer based on Human Face using CNN and Bottleneck Transformer Encoder, IWIS2023, Ulsan, Korea, Aug 9, 2023.</li>
			<li>Xuan-Thuy Vo, <strong>Duy-Linh Nguyen</strong>, Adri Priadana, and Kang-Hyun Jo, Hierarchical Vision Transformers with Shuffled Local Self-Attentions, IWIS2023, Ulsan, Korea, Aug 9, 2023.</li>
			<li><strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Adri Priadana, Kang-Hyun Jo, Car Detector Based on YOLOv5 for Parking Management, CITA 2023, Danang, Vietnam, Jul 28, 2023.</li>
			<li>Xuan-Thuy Vo, Jehwan Choi, <strong>Duy-Linh Nguyen</strong>, Adri Priadana, and Kang-Hyun Jo, Unifying Local and Global Fourier Features for Image Classification, ISIE 2023, Helsinki, Finland, Jun 19, 2023.</li>
			<li>Adri Priadana, Muhamad Dwisnanto Putro, <strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Kang-Hyun Jo, Age Group Recognizer based on Human Face Supporting Smart Digital Advertising Platforms, ISIE 2023, Helsinki, Finland, Jun 19, 2023.</li>
			<li><strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Adri Priadana, Kang-Hyun Jo, YOLO5PKLot: A Parking Lot Detection Network Based on Improved YOLOv5 for Smart Parking Management System, IW-FCV 2023, Yeosu, South Korea, Feb 20, 2023.</li>
			<li>Xuan-Thuy Vo, <strong>Duy-Linh Nguyen</strong>, Adri Priadana, and Kang-Hyun Jo, Dynamic Circular Convolution for Image Classification, IW-FCV 2023, Yeosu, South Korea, Feb 20, 2023. </li>
   			<li>Adri Priadana, Muhamad Dwisnanto Putro, <strong>Duy-Linh Nguyen</strong>, Xuan-Thuy Vo, Kang-Hyun Jo, Human Face Detector with Gender Identification by Split-based Inception Block and Regulated Attention Module, IW-FCV 2023, Yeosu, South Korea, Feb 20, 2023.</li>
		</ol>
	</div>
	
	<div>
		<h3> 2022</h3>
		<ol>
			<li>Muhamad Dwisnanto Putro, <strong>Duy-Linh Nguyen</strong>, Adri Priadana, Kang-Hyun Jo, An Efficient Multi-view Facial Expression Classifier Implementing on Edge Device, ACIIDS22, Ho Chi Minh, Viet Nam, Nov 28, 2022.</li>
			<li>Tran Tien Dat, Xuan-Thuy Vo, <strong>Duy-Linh Nguyen</strong>, Kang-Hyun Jo, Combination of Deep Learner Network with Transformer for 3D Human Pose Estimation, ICCAS 2022, Busan, Korea, Nov 27, 2022.</li>
			<li>Xuan-Thuy Vo, Tran Tien Dat, <strong>Duy-Linh Nguyen</strong>, Adri Priadana, and Kang-Hyun Jo, Balancing Multiple Object Tracking Objectives based on Learned Weighting Factors, MAPR 2022, Phu Quoc Island, Vietnam, Oct 13, 2022.</li>
			<li><strong>Duy-Linh Nguyen</strong>, Muhamad Dwisnanto Putro, Xuan-Thuy Vo, Tran Tien Dat, Kang-Hyun Jo, Fire Warning Based on Convolutional Neural Network and Inception Mechanism, MAPR 2022, Phu Quoc Island, Vietnam, Oct 13, 2022.</li>
			<li>Tran Tien Dat, Xuan-Thuy Vo, <strong>Duy-Linh Nguyen</strong>, Kang-Hyun Jo, Efficient High-Resolution Network for Human Pose Estimation, IWIS 2022, University of Ulsan, Ulsan, South Korea, Aug 17, 2022.</li>
			<li><strong>Duy-Linh Nguyen</strong>, Muhamad Dwisnanto Putro, Xuan-Thuy Vo, Tran Tien Dat, Kang-Hyun Jo, Robust Hand Detection Based on Convolutional Neural Network and Attention Module, IWIS 2022, University of Ulsan, Ulsan, South Korea, Aug 17, 2022.</li>
			<li>Xuan-Thuy Vo, Tran Tien Dat, <strong>Duy-Linh Nguyen</strong>, and Kang-Hyun Jo, A Study on Efficient Multi-task Networks for Multiple Object Tracking, IWIS 2022, University of Ulsan, Ulsan, South Korea, Aug 17, 2022.</li>
			<li>Muhamad Dwisnanto Putro, Adri Priadana,<strong> Duy-Linh Nguyen</strong>, Kang-Hyun Jo, A Real-time Face Detector on CPU Using Efficient Transformer, IWIS 2022, University of Ulsan, Ulsan, South Korea, Aug 17, 2022.</li>
			<li>Xuan-Thuy Vo, Tran Tien Dat, <strong>Duy-Linh Nguyen</strong>, and Kang-Hyun Jo, Multi-level Feature Reweighting and Fusion for Instance Segmentation, INDIN 2022, Perth, Australia, Jul 25, 2022.</li>
			<li>Muhamad Dwisnanto Putro, Adri Priadana,<strong> Duy-Linh Nguyen</strong>, Kang-Hyun Jo, A Faster Real-time Face Detector Support Smart Digital Advertising on Low-cost Computing Device, Advanced Intelligent Mechatronics (AIM), Sapporo, Hokkaido, Japan, Jul 11, 2022. </li>
			<li>Muhamad Dwisnanto Putro, <strong>Duy-Linh Nguyen</strong>, Adri Priadana, Kang-Hyun Jo, Fast Person Detector with Efficient Multi-level Contextual Block for Supporting Assistive Robot, ICPS 2022, University of Warwick in Coventry, United Kingdom, May 24, 2022. </li>
			<li>Tran Tien Dat, Xuan-Thuy Vo, <strong>Duy-Linh Nguyen</strong>, Kang-Hyun Jo, High-Resolution Network with Attention Module for Human Pose Estimation, ASCC 2022, Jeju, Korea, May 4, 2022.</li>
			<li>Muhamad Dwisnanto Putro, <strong>Duy-Linh Nguyen</strong>, Kang-Hyun Jo, A CPU-based Pedestrian Detector using Deep Learning for Intelligent Surveillance Systems, ICIT 2022, Shanghai, China , Mar 27, 2022.</li>
			<li>Xuan-Thuy Vo, Van-Dung Hoang, <strong>Duy-Linh Nguyen</strong>, and Kang-Hyun Jo, Pedestrian Head Detection and Tracking via Global Vision Transformer, IW-FCV 2022, Hiroshima, Japan, Feb 21, 2022. </li>
			<li><strong>Duy-Linh Nguyen</strong>, Muhamad Dwisnanto Putro, Xuan-Thuy Vo, Kang-Hyun Jo, Convolutional Neural Network Design for Eye Detection under Low-illumination, IW-FCV 2022, Hiroshima, Japan, Feb 21, 2022.</li>
			<li>Binh-Giang Tran and <strong>Duy-Linh Nguyen</strong>, Simple and Efficient Convolutional Neural Network for Trash Classification, RICE, Hung Yen, Vietnam, March 2022.</li>
		</ol>
	</div>
	
	<div>
		<h3> 2021</h3>
		<ol>
			<li><strong>Duy-Linh Nguyen</strong>, Muhamad Dwisnanto, PutroKang-Hyun Jo, Light-weight Convolutional Neural Network for Distracted Driver Classification, IECON 2021, Toronto, Canada, Oct 13, 2021.</li>
			<li><strong>Duy-Linh Nguyen</strong>, Muhamad Dwisnanto Putro, Kang-Hyun Jo, Distracted Driver Recognizer with Simple and Efficient Convolutional Neural Network for Real-time System, ICCAS2021, Jeju, Korea, Oct 12, 2021.</li>
			<li>Muhamad Dwisnanto Putro, <strong>Duy-Linh Nguyen</strong>, Kang-Hyun Jo, A Fast Real-time Facial Expression Classifier Deep Learning-based for Human-robot Interaction, ICCAS2021, Jeju, Korea, Oct 12, 2021.</li>
			<li>Muhamad Dwisnanto Putro, <strong>Duy-Linh Nguyen</strong>, Kang-Hyun Jo, Efficient Face Detector Using Spatial Attention Module in Real-Time Application on an Edge Device, ICIC2021, Shenzhen, Guangdong, China, Aug 12, 2021.</li>
			<li>Xuan-Thuy Vo, Tran Tien Dat, <strong>Duy-Linh Nguyen</strong> and Kang-Hyun Jo, Regression-Aware Classification Feature for Pedestrian Detection and Tracking in Video Surveillance Systems, ICIC2021, Shenzhen, Guangdong, China, Aug 12, 2021</li>.
			<li>Xuan-Thuy Vo, Tran Tien Dat, <strong>Duy-Linh Nguyen</strong>, and Kang-Hyun Jo, Dynamic Multi-Loss Weighting for Multiple People Tracking in Video Surveillance Systems, INDIN2021, Palma de Mallorca, Spain, Jul 21, 2021.</li>
			<li><strong>Duy-Linh Nguyen</strong>, Muhamad Dwisnanto Putro, Xuan-Thuy Vo, Kang-Hyun Jo, Triple Detector based on Feature Pyramid Network for License Plate Detection and Recognition System in Unusual Conditions, ISIE 2021, Miyako Messe, Kyoto, Japan, Jun 20, 2021.</li>
			<li><strong>Duy-Linh Nguyen</strong>, Muhamad Dwisnanto PutroKang-Hyun Jo, Eye State Recognizer Using Light-weight Architecture for Drowsiness Warning, ACIIDS 2021, Phuket, Thailand, Apr 7, 2021.</li>
			<li>Muhamad Dwisnanto Putro,<strong>Duy-Linh Nguyen</strong>,Kang-Hyun Jo, Real-time Multi-view Face Masks Detector on Edge Device For Supporting Service Robots in the COVID-19 Pandemic, ACIIDS 2021, Phuket, Thailand, Apr 7, 2021.</li>
			<li>Xuan-Thuy Vo, Tran Tien Dat, <strong>Duy-Linh Nguyen</strong> and Kang-Hyun Jo, Stair-step Feature Pyramid Networks for Object Detection, IW - FCV 2021, Daegu, South Korea, Feb 21, 2021.</li>
			<li>Tran Tien Dat, Xuan-Thuy Vo,<strong> Duy-Linh Nguyen</strong>, Kang-Hyun Jo, Effcient Spatial-Attention module for human pose estimation, IW - FCV 2021, Daegu, South Korea, Feb 21, 2021.</li>
		</ol>
	</div>
	
	<div>
		<h3> 2020</h3>
		<ol>
			<li>Muhamad Dwisnanto Putro,<strong>Duy-Linh Nguyen</strong>, Kang-Hyun Jo, SGCNet: Spatial-Global Context Attention Network for Real-time Facial Expression Recognition, IWIS 2020, Ulsan, Korea, Dec 13, 2020.</li>
			<li><strong>Duy-Linh Nguyen</strong>, Muhamad Dwisnanto, PutroKang-Hyun Jo, Proposed Light-weight Convolutional Neural Networks for Real-time Hand Gesture Detector, IWIS 2020, Ulsan, Korea, Dec 13, 2020.</li>
			<li>D<strong>uy-Linh Nguyen</strong>, Muhamad Dwisnanto Putro, Kang-Hyun Jo, Human Eye Detector with Light-weight and Efficient Convolutional Neural Network, ICCCI 2020, Da Nang, Viet Nam, Nov 30, 2020.</li>
			<li><strong>Duy-Linh Nguyen</strong>, Muhamad Dwisnanto Putro, Kang-Hyun Jo, Eyes Status Detector Based on Light-weight Convolutional Neural Networks supporting for Drowsiness Detection System, IECON 2020, Marina Bay Sands Expo and Convention Centre, Singapore, Oct 18, 2020.</li>
			<li>Muhamad Dwisnanto Putro,<strong>Duy-Linh Nguyen</strong>,Kang-Hyun Jo, A Dual Attention Module for Real-time Facial Expression Recognition, IECON 2020, Marina Bay Sands Expo and Convention Centre, Singapore, Oct 18, 2020.</li>
			<li><strong>Duy-Linh Nguyen</strong>, Muhamad Dwisnanto Putro, Kang-Hyun Jo, Hand Detector based on Efficient and Lighweight Convolutional Neural Network, ICCAS 2020, Busan, Korea, Oct 13, 2020.</li>
			<li>Muhamad Dwisnanto Putro,<strong>Duy-Linh Nguyen</strong>,Kang-Hyun Jo, Fast Eye Detector Using CPU Based Lightweight Convolutional Neural Network, ICCAS 2020, Busan, Korea, Oct 13, 2020.</li>
			<li>Muhamad Dwisnanto Putro,<strong>Duy-Linh Nguyen</strong>,Kang-Hyun Jo, Lightweight Convolutional Neural Network for Real-Time Face Detector on CPU Supporting Interaction of Service Robot, HSI 2020, Tokyo, Japan, Jun 6, 2020.</li>
		</ol>
	</div>
	</div>

    </section><!-- /Publication Section -->

    <!-- Skills Section -->
    <section id="skills" class="skills section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Skills</h2>
        <!-- <p>Necessitatibus eius consequatur ex aliquid fuga eum quidem sint consectetur velit</p> -->
      </div><!-- End Section Title -->

      <div class="container" data-aos="fade-up" data-aos-delay="100">

        <div class="row skills-content skills-animation">

          <div class="col-lg-6">

            <div class="progress">
              <span class="skill"><span>Python</span> <i class="val">100%</i></span>
              <div class="progress-bar-wrap">
                <div class="progress-bar" role="progressbar" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"></div>
              </div>
            </div><!-- End Skills Item -->

            <div class="progress">
              <span class="skill"><span>CSS</span> <i class="val">90%</i></span>
              <div class="progress-bar-wrap">
                <div class="progress-bar" role="progressbar" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div>
              </div>
            </div><!-- End Skills Item -->

            <div class="progress">
              <span class="skill"><span>JavaScript</span> <i class="val">85%</i></span>
              <div class="progress-bar-wrap">
                <div class="progress-bar" role="progressbar" aria-valuenow="85" aria-valuemin="0" aria-valuemax="100"></div>
              </div>
            </div><!-- End Skills Item -->

          </div>

          <div class="col-lg-6">

            <div class="progress">
              <span class="skill"><span>PHP/HTML</span> <i class="val">95%</i></span>
              <div class="progress-bar-wrap">
                <div class="progress-bar" role="progressbar" aria-valuenow="95" aria-valuemin="0" aria-valuemax="100"></div>
              </div>
            </div><!-- End Skills Item -->

            <div class="progress">
              <span class="skill"><span>C, C#, C++</span> <i class="val">90%</i></span>
              <div class="progress-bar-wrap">
                <div class="progress-bar" role="progressbar" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100"></div>
              </div>
            </div><!-- End Skills Item -->

            <div class="progress">
              <span class="skill"><span>Photoshop/Corel Draw</span> <i class="val">95%</i></span>
              <div class="progress-bar-wrap">
                <div class="progress-bar" role="progressbar" aria-valuenow="95" aria-valuemin="0" aria-valuemax="100"></div>
              </div>
            </div><!-- End Skills Item -->

          </div>

        </div>

      </div>

    </section><!-- /Skills Section -->

    <!-- Resume Section -->
    <section id="resume" class="resume section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Resume</h2>
        <!-- <p>Magnam dolores commodi suscipit. Necessitatibus eius consequatur ex aliquid fuga eum quidem. Sit sint consectetur velit. Quisquam quos quisquam cupiditate. Et nemo qui impedit suscipit alias ea. Quia fugiat sit in iste officiis commodi quidem hic quas.</p> -->
      </div><!-- End Section Title -->

      <div class="container">

        <div class="row">

          <div class="col-lg-6" data-aos="fade-up" data-aos-delay="100">
            <h3 class="resume-title">Sumary</h3>

            <div class="resume-item pb-0">
              <h4>Dr. Duy-linh nguyen </h4>
              <p><em>Postdoctoral Researcher in AI and Computer Vision</em></p>
              <ul>
                <li>
                  <p>Intelligent Systems Laboratory (ISlab), <br>
                    Department of  Electrical, Electronic and Computer Engineering, University of Ulsan, <br>
                    7-104, 93 Daehak-ro,  Nam-gu, Ulsan, Korea.</p>
                </li>
                <li>(+82) 010-5953-5249</li>
                <li>ndlinh301@mail.ulsan.ac.kr</li>
              </ul>
            </div>
            <!-- Edn Resume Item -->

            <h3 class="resume-title">Education</h3>
            <div class="resume-item">
              <h4>Ph.D. in Electrical Engineering</h4>
              <h5>Aug. 18, 2023</h5>
              <p><em>University of Ulsan, South Korea</em></p>
              <p>Thesis: “Driver Eye Status Monitoring System Based on Lightweight Convolutional Neural Network Architectures for Low-computing Devices”, </p>
              <p>Advisor: Prof. Kang-Hyun Jo</p>
            </div>
            <!-- Edn Resume Item -->

            <div class="resume-item">
              <h4>Master in Computer Science</h4>
              <h5>Dec. 31, 2014</h5>
              <p><em>Danang University of Science and Technology, Vietnam</em></p>
              <p>Thesis: “Constructing software for finding the similarities among documents”, </p>
              <p>Advisor: Assoc. Prof. Vo Trung Hung</p>
            </div>
            <!-- Edn Resume Item -->
			
			            <div class="resume-item">
              <h4>Engineer in Applied Informatics</h4>
              <h5>Jun.30, 2010</h5>
              <p><em>Vinh University of Technology Education, Vietnam</em></p>
              <p>Thesis: “Research Learning Object, Reload Editor tool to build lectures for distance learning”, </p>
              <p>Advisor: MSc. Tran Thanh Phong</p>
			            </div>
			            <!-- Edn Resume Item -->

          </div>

          <div class="col-lg-6" data-aos="fade-up" data-aos-delay="200">
            <h3 class="resume-title">Professional Experience</h3>
            <div class="resume-item">
              <h4>Postdoctoral researcher</h4>
              <h5>Aug. 2023 – Present</h5>
              <p><em>Intelligent Systems Laboratory (ISLAB), Department of Electrical, Electronic and Computer Engineering, University of Ulsan </em></p>
              <ul>
                <li>Lead of the projects</li>
                <li>Researcher </li>
              </ul>
            </div>
            <!-- Edn Resume Item -->

            <div class="resume-item">
              <h4>Ph.D. student</h4>
              <h5>Sep. 2018 – Aug. 2023</h5>
              <p><em>Intelligent Systems Laboratory (ISLAB), Department of Electrical, Electronic and Computer Engineering, University of Ulsan</em></p>
              <ul>
                <li>Ph.D student</li>
                <li>Researcher</li>
              </ul>
            </div>
            <!-- Edn Resume Item -->
			
			<div class="resume-item">
              <h4>Researcher Member</h4>
              <h5>Jul. 2016 – Sep. 2018</h5>
              <p><em>Intelligent Systems Laboratory (ISLAB), Quang Binh University, Quang Binh province, Vietnam</em></p>
              <ul>

                <li>Researcher</li>
              </ul>
            </div>
			<!-- Edn Resume Item -->
			
			<div class="resume-item">
              <h4>Lecturer</h4>
              <h5>Jul. 2013 – Sep. 2018</h5>
              <p><em>Faculty of Engineering - Information Technology, Quang Binh University, Quang Binh province, Vietnam</em></p>
              <ul>
                <li>Lecturer</li>
                <li>Researcher</li>
              </ul>
			</div>
			<!-- Edn Resume Item -->
			
		    <div class="resume-item">
              <h4>Lecturer</h4>
              <h5>Jul. 2010 – Jul. 2013</h5>
              <p><em>Faculty of Math - Information Technology, Quang Binh University, Quang Binh province, Vietnam</em></p>
              <ul>
                <li>Lecturer</li>
                <li>Researcher</li>
              </ul>
			</div>
		    <!-- Edn Resume Item -->
			
		    <div class="resume-item">
              <h4>Employee</h4>
              <h5>Jul. 2007 – Nov. 2008</h5>
              <p><em>Computer Hardware Company, Quang Binh province, Vietnam</em></p>
              <ul>
                <li>Technician</li>
              </ul>
			</div>
		    <!-- Edn Resume Item -->
          </div>

        </div>

      </div>

    </section><!-- /Resume Section -->

    <!-- Portfolio Section -->
    <section id="portfolio" class="portfolio section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Research Activities </h2>
        <!-- <p>Magnam dolores commodi suscipit. Necessitatibus eius consequatur ex aliquid fuga eum quidem. Sit sint consectetur velit. Quisquam quos quisquam cupiditate. Et nemo qui impedit suscipit alias ea. Quia fugiat sit in iste officiis commodi quidem hic quas.</p> -->
		         <ul style="text-align:left">
                <li>Reviewer (IEEE TII, IEEE TIE, IEEE SENSORS, IEEE ACCESS, VJCS, TJIT) </li>
                <li>Session Organizer and Chair (CITA, ISIE, IWIS) </li>
                <li>Presenter (ISIE, IECON, CITA, ICCCI, HSI, IWIS, IW-FCV, MAPR, ACIIDS) </li>
				<li>Project Leader and Member</li>
              </ul>
      </div><!-- End Section Title -->


    </section><!-- /Portfolio Section -->

    <!-- Services Section -->
    <section id="services" class="services section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Awards</h2>

      </div><!-- End Section Title -->

      <div class="container">

        <div class="row gy-4">

          <div class="col-lg-4 col-md-6" data-aos="fade-up" data-aos-delay="100">
            <div class="service-item item-cyan position-relative">
              <div class="icon">
                <svg width="100" height="100" viewBox="0 0 600 600" xmlns="http://www.w3.org/2000/svg">
                  <path stroke="none" stroke-width="0" fill="#f5f5f5" d="M300,521.0016835830174C376.1290562159157,517.8887921683347,466.0731472004068,529.7835943286574,510.70327084640275,468.03025145048787C554.3714126377745,407.6079735673963,508.03601936045806,328.9844924480964,491.2728898941984,256.3432110539036C474.5976632858925,184.082847569629,479.9380746630129,96.60480741107993,416.23090153303,58.64404602377083C348.86323505073057,18.502131276798302,261.93793281208167,40.57373210992963,193.5410806939664,78.93577620505333C130.42746243093433,114.334589627462,98.30271207620316,179.96522072025542,76.75703585869454,249.04625023123273C51.97151888228291,328.5150500222984,13.704378332031375,421.85034740162234,66.52175969318436,486.19268352777647C119.04800174914682,550.1803526380478,217.28368757567262,524.383925680826,300,521.0016835830174"></path>
                </svg>
				<i><img src="assets/img/Awards/CITA23.jpg" height="120" width="200"></i>
                <!-- <i class="bi bi-activity"></i>-->
              </div>
              <a href="#" class="stretched-link">
                <h3>Best paper award</h3>
              </a>
              <p>The 12th Conference on Information technology and its applications (CITA 2023),<br>
			  Danang, Vietnam</p>
            </div>
          </div><!-- End Service Item -->

          <div class="col-lg-4 col-md-6" data-aos="fade-up" data-aos-delay="200">
            <div class="service-item item-orange position-relative">
              <div class="icon">
                <svg width="100" height="100" viewBox="0 0 600 600" xmlns="http://www.w3.org/2000/svg">
                  <path stroke="none" stroke-width="0" fill="#f5f5f5" d="M300,582.0697525312426C382.5290701553225,586.8405444964366,449.9789794690241,525.3245884688669,502.5850820975895,461.55621195738473C556.606425686781,396.0723002908107,615.8543463187945,314.28637112970534,586.6730223649479,234.56875336149918C558.9533121215079,158.8439757836574,454.9685369536778,164.00468322053177,381.49747125262974,130.76875717737553C312.15926192815925,99.40240125094834,248.97055460311594,18.661163978235184,179.8680185752513,50.54337015887873C110.5421016452524,82.52863877960104,119.82277516462835,180.83849132639028,109.12597500060166,256.43424936330496C100.08760227029461,320.3096726198365,92.17705696193138,384.0621239912766,124.79988738764834,439.7174275375508C164.83382741302287,508.01625554203684,220.96474134820875,577.5009287672846,300,582.0697525312426"></path> 
                </svg>
                <i><img src="assets/img/Awards/IW-FCV24.jpg" height="120" width="200"></i>              </div>
              <a href="#" class="stretched-link">
                <h3>Exellent Student Research Paper Award </h3>
              </a>
              <p>The 30th International Workshop on Frontiers of Computer Vision (IW-FCV2024), <br> Tokyo, Japan</p>
            </div>
          </div><!-- End Service Item -->

          <div class="col-lg-4 col-md-6" data-aos="fade-up" data-aos-delay="300">
            <div class="service-item item-teal position-relative">
              <div class="icon">
                <svg width="100" height="100" viewBox="0 0 600 600" xmlns="http://www.w3.org/2000/svg">
                  <path stroke="none" stroke-width="0" fill="#f5f5f5" d="M300,541.5067337569781C382.14930387511276,545.0595476570109,479.8736841581634,548.3450877840088,526.4010558755058,480.5488172755941C571.5218469581645,414.80211281144784,517.5187510058486,332.0715597781072,496.52539010469104,255.14436215662573C477.37192572678356,184.95920475031193,473.57363656557914,105.61284051026155,413.0603344069578,65.22779650032875C343.27470386102294,18.654635553484475,251.2091493199835,5.337323636656869,175.0934190732945,40.62881213300186C97.87086631185822,76.43348514350839,51.98124368387456,156.15599469081315,36.44837278890362,239.84606092416172C21.716077023791087,319.22268207091537,43.775223500013084,401.1760424656574,96.891909868211,461.97329694683043C147.22146801428983,519.5804099606455,223.5754009179313,538.201503339737,300,541.5067337569781"></path>
                </svg>
                <i><img src="assets/img/Awards/IWIS24.jpg" height="120" width="200"></i>              </div>
              <a href="#" class="stretched-link">
                <h3>Best Presentation Paper Award</h3>
              </a>
              <p>The International Workshop on Intelligent Systems (IWIS 2024), <br> Ulsan, South Korea</p>
            </div>
          </div><!-- End Service Item -->

          <div class="col-lg-4 col-md-6" data-aos="fade-up" data-aos-delay="400">
            <div class="service-item item-red position-relative">
              <div class="icon">
                <svg width="100" height="100" viewBox="0 0 600 600" xmlns="http://www.w3.org/2000/svg">
                  <path stroke="none" stroke-width="0" fill="#f5f5f5" d="M300,503.46388370962813C374.79870501325706,506.71871716319447,464.8034551963731,527.1746412648533,510.4981551193396,467.86667711651364C555.9287308511215,408.9015244558933,512.6030010748507,327.5744911775523,490.211057578863,256.5855673507754C471.097692560561,195.9906835881958,447.69079081568157,138.11976852964426,395.19560036434837,102.3242989838813C329.3053358748298,57.3949838291264,248.02791733380457,8.279543830951368,175.87071277845988,42.242879143198664C103.41431057327972,76.34704239035025,93.79494320519305,170.9812938413882,81.28167332365135,250.07896920659033C70.17666984294237,320.27484674793965,64.84698225790005,396.69656628748305,111.28512138212992,450.4950937839243C156.20124167950087,502.5303643271138,231.32542653798444,500.4755392045468,300,503.46388370962813"></path>
                </svg>
                <i><img src="assets/img/Awards/IW-FCV 24-Adri.png" height="120" width="200"></i>              </div>
              <a href="#" class="stretched-link">
                <h3>Best Student Paper Award</h3>
              </a>
              <p>The 30th International Workshop on Frontiers of Computer Vision (IW-FCV2024), <br> Toky, Japan</p>
              <a href="#" class="stretched-link"></a>
            </div>
          </div><!-- End Service Item -->

          <div class="col-lg-4 col-md-6" data-aos="fade-up" data-aos-delay="500">
            <div class="service-item item-indigo position-relative">
              <div class="icon">
                <svg width="100" height="100" viewBox="0 0 600 600" xmlns="http://www.w3.org/2000/svg">
                  <path stroke="none" stroke-width="0" fill="#f5f5f5" d="M300,532.3542879108572C369.38199826031484,532.3153073249985,429.10787420159085,491.63046689027357,474.5244479745417,439.17860296908856C522.8885846962883,383.3225815378663,569.1668002868075,314.3205725914397,550.7432151929288,242.7694973846089C532.6665558377875,172.5657663291529,456.2379748765914,142.6223662098291,390.3689995646985,112.34683881706744C326.66090330228417,83.06452184765237,258.84405631176094,53.51806209861945,193.32584062364296,78.48882559362697C121.61183558270385,105.82097193414197,62.805066853699245,167.19869350419734,48.57481801355237,242.6138429142374C34.843463184063346,315.3850353017275,76.69343916112496,383.4422959591041,125.22947124332185,439.3748458443577C170.7312796277747,491.8107796887764,230.57421082200815,532.3932930995766,300,532.3542879108572"></path>
                </svg>
                <i><img src="assets/img/Awards/MAPR22.jpg" height="120" width="200"></i>              </div>
              <a href="#" class="stretched-link">
                <h3>Best Paper Award</h3>
              </a>
              <p>the 5th International Conference on Multimedia Analysis and Pattern Recognition (MAPR2022), <br> Phu Quoc, Vietnam</p>
              <a href="#" class="stretched-link"></a>
            </div>
          </div><!-- End Service Item -->

          <div class="col-lg-4 col-md-6" data-aos="fade-up" data-aos-delay="600">
            <div class="service-item item-pink position-relative">
              <div class="icon">
                <svg width="100" height="100" viewBox="0 0 600 600" xmlns="http://www.w3.org/2000/svg">
                  <path stroke="none" stroke-width="0" fill="#f5f5f5" d="M300,566.797414625762C385.7384707136149,576.1784315230908,478.7894351017131,552.8928747891023,531.9192734346935,484.94944893311C584.6109503024035,417.5663521118492,582.489472248146,322.67544863468447,553.9536738515405,242.03673114598146C529.1557734026468,171.96086150256528,465.24506316201064,127.66468636344209,395.9583748389544,100.7403814666027C334.2173773831606,76.7482773500951,269.4350130405921,84.62216499799875,207.1952322260088,107.2889140133804C132.92018162631612,134.33871894543012,41.79353780512637,160.00259165414826,22.644507872594943,236.69541883565114C3.319112789854554,314.0945973066697,72.72355303640163,379.243833228382,124.04198916343866,440.3218312028393C172.9286146004772,498.5055451809895,224.45579914871206,558.5317968840102,300,566.797414625762"></path>
                </svg>
                <i><img src="assets/img/Awards/STAIS23.jpeg" height="120" width="200"></i>              </div>
              <a href="#" class="stretched-link">
                <h3>Excellent Paper Award</h3>
              </a>
              <p>STAIS2023, <br> Vinh, Vietnam</p>
              <a href="#" class="stretched-link"></a>
            </div>
          </div><!-- End Service Item -->

        </div>

      </div>

    </section><!-- /Services Section -->

    <!-- Testimonials Section -->
    <section id="partners" class="testimonials section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Supervisor and Partners </h2>
        <!-- <p>Necessitatibus eius consequatur ex aliquid fuga eum quidem sint consectetur velit</p>-->
</div>
      <!-- End Section Title -->

      <div class="container" data-aos="fade-up" data-aos-delay="100">

        <div class="swiper init-swiper">
          <script type="application/json" class="swiper-config">
            {
              "loop": true,
              "speed": 600,
              "autoplay": {
                "delay": 5000
              },
              "slidesPerView": "auto",
              "pagination": {
                "el": ".swiper-pagination",
                "type": "bullets",
                "clickable": true
              }
            }
          </script>
          <div class="swiper-wrapper">

            <div class="swiper-slide">
              <div class="testimonial-item">
                <div class="row gy-4 justify-content-center">
                  <div class="col-lg-6">
                    <div class="testimonial-content">
                      <p>
                        <i class="bi bi-quote quote-icon-left"></i>
                        <span>Prof. KANG-HYUN JO received a
Ph.D. in Computer-controlled Machinery from
Osaka University, Osaka, Japan, in 1997. After one year of experience with ETRI as a Postdoc toral Research Fellow, he joined the School of
Electrical Engineering, University of Ulsan, Ulsan, South Korea, where he is currently the Faculty Dean of the School of Electrical Engineering.
His research interests include computer vision, robotics, autonomous vehicles, and ambient intelligence. Dr. Jo was the Director or an AdCom Member of the Institute of
Control, Robotics, and Systems and the Society of Instrument and Control
Engineers; the Chair of the IEEE IES Technical Committee on Human
Factors; an AdCom Member and the Secretary until 2019. He has also been
involved in organizing many international conferences, such as the International Workshop on Frontiers of Computer Vision, the International Conference on Intelligent Computation, the International Conference on Industrial
Technology, the International Conference on Human System Interactions,
and the Annual Conference of the IEEE Industrial Electronics Society. He is
currently an Editorial Board Member for international journals, such as the
International Journal of Control, Automation, and Systems and Transactions
on Computational Collective Intelligence.</span>
                        <i class="bi bi-quote quote-icon-right"></i>                      </p>
                      <h3>Prof. Kang-Hyun Jo </h3>
					  <h4>Supervisor </h4>
                      <h4>Department of Electrical, Electronic and Computer Engineering, University of Ulsan, South Korea </h4>
                      <div class="stars">
                        <i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i>
                      </div>
                    </div>
                  </div>
                  <div class="col-lg-2 text-center">
                    <img src="assets/img/Co-authors/Kang-Hyun_Jo.jpg" class="img-fluid testimonial-img" alt="">
                  </div>
                </div>
              </div>
            </div><!-- End testimonial item -->

            <div class="swiper-slide">
              <div class="testimonial-item">
                <div class="row gy-4 justify-content-center">
                  <div class="col-lg-6">
                    <div class="testimonial-content">
                      <p>
                        <i class="bi bi-quote quote-icon-left"></i>
                        <span>Dr. Xuan-Thuy Vo received a B.S. degree in Electrical and Electronic Engineering from University of Science and Technology at the University of DaNang, Da Nang, Vietnam, in 2018. He received a Ph.D. at the Department of Electrical, Electronic, and Computer Engineering, University of Ulsan, South Korea, in 2024. He is currently working in the Intelligent Systems Laboratory, University of Ulsan as a Postdoctoral Researcher. His current research interests include computer vision and deep learning with a focus on efficient vision architectures, object detection, object segmentation, multiple object tracking, human action recognition, and multimodal learning.</span>
                        <i class="bi bi-quote quote-icon-right"></i>                      </p>
                      <h3>Dr. Xuan-Thuy Vo</h3>
                      <h4>Department of Electrical, Electronic and Computer Engineering, University of Ulsan, South Korea</h4>
                      <div class="stars">
                        <i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i>
                      </div>
                    </div>
                  </div>
                  <div class="col-lg-2 text-center"><img src="assets/img/Co-authors/Xuan-Thuy_Vo.jpg" class="img-fluid testimonial-img" alt=""></div>
                </div>
              </div>
            </div><!-- End testimonial item -->

            <div class="swiper-slide">
              <div class="testimonial-item">
                <div class="row gy-4 justify-content-center">
                  <div class="col-lg-6">
                    <div class="testimonial-content">
                      <p>
                        <i class="bi bi-quote quote-icon-left"></i>
                        <span>Mr. Adri Priadana received a Bachelor of Informatics Engineering (S.Kom.) degree from Amikom Yogyakarta University, Yogyakarta, Indonesia, in 2013, and a M.Cs. degree from the Department of Computer Science, Gadjah Mada University, Yogyakarta, Indonesia, in 2016. He is currently working toward a Ph.D. in Electrical Engineering in the Department of Electrical, Electronic, and Computer Engineering, University of Ulsan, Ulsan, South Korea. In 2018, he joined the Department of Engineering and Information Technology, Jenderal Achmad Yani Yogyakarta University. His current research interests include computer vision and deep learning, focusing on faces and facial attributes, and human action recognition.</span>
                        <i class="bi bi-quote quote-icon-right"></i>                      </p>
                      <h3>Mr. Adri Priadana</h3>
                      <h4>Department of Electrical, Electronic and Computer Engineering, University of Ulsan, South Korea</h4>
                      <div class="stars">
                        <i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i>
                      </div>
                    </div>
                  </div>
                  <div class="col-lg-2 text-center">
                    <img src="assets/img/Co-authors/AdriPriadana.jpg" class="img-fluid testimonial-img" alt="">
                  </div>
                </div>
              </div>
            </div><!-- End testimonial item -->

            <div class="swiper-slide">
              <div class="testimonial-item">
                <div class="row gy-4 justify-content-center">
                  <div class="col-lg-6">
                    <div class="testimonial-content">
                      <p>
                        <i class="bi bi-quote quote-icon-left"></i>
                        <span>Mr. Jehwan Choi received a Bachelor of Engineering degree in Electrical and Electronic Engineering from the University of Ulsan, Ulsan, South Korea, in 2021, and a Master’s degree in Electrical, Electronic, and Computer Engineering from the same university in 2023. He is currently pursuing a Ph.D. at the University of Ulsan and is affiliated with the Intelligent System Laboratory (ISLab), Department of Electrical, Electronic, and Computer Engineering. His research interests include AI, computer vision, and lightweight deep learning models for real-time drone surveillance and vehicle tracking applications.</span>
                        <i class="bi bi-quote quote-icon-right"></i>                      </p>
                      <h3>Mr. Jehwan Choi</h3>
                      <h4>Department of Electrical, Electronic and Computer Engineering, University of Ulsan, South Korea</h4>
                      <div class="stars">
                        <i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i>
                      </div>
                    </div>
                  </div>
                  <div class="col-lg-2 text-center">
                    <img src="assets/img/Co-authors/JehwanChoi.jpg" class="img-fluid testimonial-img" alt="">
                  </div>
                </div>
              </div>
            </div><!-- End testimonial item -->

            <div class="swiper-slide">
              <div class="testimonial-item">
                <div class="row gy-4 justify-content-center">
                  <div class="col-lg-6">
                    <div class="testimonial-content">
                      <p>
                        <i class="bi bi-quote quote-icon-left"></i>
                        <span></span>Dr. Muhamad Dwisnanto Putro received a B.Eng. (S.T.) degree in electrical engineering from Sam Ratulangi University, Manado, Indonesia, in 2010, and a M.Eng. degree from the Department of Electrical Engineering, Gadjah Mada University, Yogyakarta, Indonesia, in 2012. He graduated Ph.D. degree with the Department of Electrical, Electronic, and Computer Engineering, University of Ulsan, South Korea. In 2013, he joined the Department of Electrical Engineering, Sam Ratulangi University, as an Assistant Professor. His current research interests include computer vision and deep learning, which focuses on robotic vision and perception. </p>
                      <h3>Dr. Muhamad Dwisnanto Putro</h3>
                      <h4>Department of Electrical Engineering, Sam Ratulangi University, Indonesia </h4>
                      <div class="stars">
                        <i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i><i class="bi bi-star-fill"></i>
                      </div>
                    </div>
                  </div>
                  <div class="col-lg-2 text-center">
                    <img src="assets/img/Co-authors/Dwisnanto_Putro.jpg" class="img-fluid testimonial-img" alt="">
                  </div>
                </div>
              </div>
            </div><!-- End testimonial item -->

          </div>
          <div class="swiper-pagination"></div>
        </div>

      </div>

    </section><!-- /Testimonials Section -->

    <!-- Contact Section -->
    <section id="contact" class="contact section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Contact</h2>
        <!-- <p>Necessitatibus eius consequatur ex aliquid fuga eum quidem sint consectetur velit</p>-->
      </div><!-- End Section Title -->

      <div class="container" data-aos="fade" data-aos-delay="100">

        <div class="row gy-4">

          <div class="col-lg-4">
            <div class="info-item d-flex" data-aos="fade-up" data-aos-delay="200">
              <i class="bi bi-geo-alt flex-shrink-0"></i>
              <div>
                <h3>Address</h3>
                <p><strong>Intelligent Systems Laboratory (ISlab)</strong>,<br>
Department of Electrical, Electronic and Computer Engineering, University of Ulsan,<br>
7-104, 93 Daehak-ro, Nam-gu, Ulsan, South Korea.</p>
              </div>
            </div><!-- End Info Item -->

            <div class="info-item d-flex" data-aos="fade-up" data-aos-delay="300">
              <i class="bi bi-telephone flex-shrink-0"></i>
              <div>
                <h3>Call Us</h3>
                <p>(+82) 010-5953-5249</p>
              </div>
            </div><!-- End Info Item -->

            <div class="info-item d-flex" data-aos="fade-up" data-aos-delay="400">
              <i class="bi bi-envelope flex-shrink-0"></i>
              <div>
                <h3>Email Us</h3>
                <p>ndlinh301@mail.ulsan.ac.kr<br>nguyenduylinhqbui@gmail.com</p>
              </div>
            </div><!-- End Info Item -->

          </div>

          <div class="col-lg-8">
            <form action="forms/contact.php" method="post" class="php-email-form" data-aos="fade-up" data-aos-delay="200">
              <div class="row gy-4">

                <div class="col-md-6">
                  <input type="text" name="name" class="form-control" placeholder="Your Name" required="">
                </div>

                <div class="col-md-6 ">
                  <input type="email" class="form-control" name="email" placeholder="Your Email" required="">
                </div>

                <div class="col-md-12">
                  <input type="text" class="form-control" name="subject" placeholder="Subject" required="">
                </div>

                <div class="col-md-12">
                  <textarea class="form-control" name="message" rows="6" placeholder="Message" required=""></textarea>
                </div>

                <div class="col-md-12 text-center">
                  <div class="loading">Loading</div>
                  <div class="error-message"></div>
                  <div class="sent-message">Your message has been sent. Thank you!</div>

                  <button type="submit">Send Message</button>
                </div>

              </div>
            </form>
          </div><!-- End Contact Form -->

        </div>

      </div>

    </section><!-- /Contact Section -->

  </main>

  <footer id="footer" class="footer position-relative light-background">
    <div class="container">
      <h3 class="sitename">Duy-Linh Nguyen</h3>
      <p>Practice makes perfect!</p>
      <div class="social-links d-flex justify-content-center">
              <a href="https://scholar.google.co.kr/citations?user=nq112_4AAAAJ&hl=en"><i class="bi bi-google"></i></a>
              <a href="https://www.linkedin.com/in/duy-linh-nguyen-619b81134/"><i class="bi bi-linkedin"></i></a>
              <a href="https://x.com/ndlinh301"><i class="bi bi-twitter-x"></i></a>
              <a href="https://www.facebook.com/nguyenduylinhlh"><i class="bi bi-facebook"></i></a>
              <a href="https://www.instagram.com/nguyenduylinhlh/"><i class="bi bi-instagram"></i></a>      
              <a href="https://www.tiktok.com/@ndlinh301"><i class="bi bi-tiktok"></i></a>
      </div>
      <div class="container">
        <div class="copyright">
          <span>Copyright</span> <strong class="px-1 sitename">Duy-Linh Nguyen</strong> <span>All Rights Reserved</span>
        </div>
        <div class="credits">
          <!-- All the links in the footer should remain intact. -->
          <!-- You can delete the links only if you've purchased the pro version. -->
          <!-- Licensing information: https://bootstrapmade.com/license/ -->
          <!-- Purchase the pro version with working PHP/AJAX contact form: [buy-url] -->
        </div>
      </div>
    </div>
  </footer>

  <!-- Scroll Top -->
  <a href="#" id="scroll-top" class="scroll-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Preloader -->
  <div id="preloader"></div>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/imagesloaded/imagesloaded.pkgd.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>

  <!-- Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>